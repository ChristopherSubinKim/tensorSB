{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "483b4065",
   "metadata": {},
   "source": [
    "## Basic examples of tensorSB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bbae65b",
   "metadata": {
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1755792684572,
     "user": {
      "displayName": "Subin Kim",
      "userId": "15547911492359629778"
     },
     "user_tz": -540
    },
    "id": "7bbae65b"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e69ceb",
   "metadata": {},
   "source": [
    "### Import tensorSB\n",
    "\n",
    "There are three types of backends: Torch, NumPy, and CuPy.\n",
    "\n",
    "Once a backend is selected, all tensors will be created using that backend.\n",
    "In most cases, you do not need to explicitly import ```Torch/NumPy/CuPy``` modules, since tensor creation and manipulation functions are abstracted and exposed through tensorSB.\n",
    "\n",
    "The backend type is controlled by the ```BACKEND_TYPE``` environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f6a3692",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9416,
     "status": "ok",
     "timestamp": 1755792707339,
     "user": {
      "displayName": "Subin Kim",
      "userId": "15547911492359629778"
     },
     "user_tz": -540
    },
    "id": "3f6a3692",
    "outputId": "ea84fd45-ba31-4cc6-dd30-e4f42c3e425d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorSB' from '/home/subini0213/cuQuantum/tensorSB/src/tensorSB/__init__.py'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import importlib\n",
    "os.environ[\"BACKEND_TYPE\"]=\"torch\"\n",
    "# os.environ[\"BACKEND_TYPE\"]=\"numpy\"\n",
    "# os.environ[\"BACKEND_TYPE\"]=\"cupy\"\n",
    "try:\n",
    "    tn.reset_backend()\n",
    "except:\n",
    "    pass\n",
    "import tensorSB as tn\n",
    "importlib.reload(tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9173b6e",
   "metadata": {},
   "source": [
    "### Backend functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f021a583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1.shape : torch.Size([1, 2, 3])\n",
      "t2.shape : torch.Size([1, 2, 5])\n",
      "t3.shape : torch.Size([2, 3, 5, 7])\n",
      "t12.shape : torch.Size([1, 2, 8])\n",
      "t1p.shape : torch.Size([2, 1, 3])\n",
      "t3r.shape : torch.Size([6, 35])\n",
      "eye7.shape : torch.Size([7, 7])\n",
      "t3rd.shape : torch.Size([35, 6])\n",
      "I.shape : torch.Size([10, 2, 5])\n",
      "I2.shape : torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "t1 = tn.backend.get_rand([1,2,3])\n",
    "t2 = tn.backend.get_rand([1,2,5])\n",
    "t3 = tn.backend.get_rand([2,3,5,7],\"uniform\")\n",
    "t12 = tn.backend.cat((t1,t2),2)\n",
    "t1p = tn.backend.permute(t1,[1,0,2])\n",
    "t3r = tn.backend.reshape(t3,[6,35])\n",
    "eye7 = tn.backend.eye(7)\n",
    "t3rd = tn.tensor.Hconj(t3r)\n",
    "I=tn.tensor.get_identity(t1,1,t2,2,[2,0,1])\n",
    "I2 = tn.tensor.get_identity(t1,1)\n",
    "\n",
    "\n",
    "# print\n",
    "print(f\"t1.shape : {t1.shape}\")\n",
    "print(f\"t2.shape : {t2.shape}\")\n",
    "print(f\"t3.shape : {t3.shape}\")\n",
    "print(f\"t12.shape : {t12.shape}\")\n",
    "print(f\"t1p.shape : {t1p.shape}\")\n",
    "print(f\"t3r.shape : {t3r.shape}\")\n",
    "print(f\"eye7.shape : {eye7.shape}\")\n",
    "print(f\"t3rd.shape : {t3rd.shape}\")\n",
    "print(f\"I.shape : {I.shape}\")\n",
    "print(f\"I2.shape : {I2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6f7b71",
   "metadata": {},
   "source": [
    "### Pauli Operators\n",
    "\n",
    "```S,I = tn.tensor.get_local_space('Spin', s)```\n",
    "\n",
    "```S``` is rank-3 tensor operator, which is spin operator of spin-s boson/fermion, and ```I``` is rank-2 identity tensor with same Hilbert space.\n",
    "\n",
    " ```S[:,:,0], S[:,:,0], S[:,:,0]``` correspond to  $\\frac{1}{\\sqrt{2}}S_{+}, S_z, \\frac{1}{\\sqrt{2}}S_{-}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "107f21e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.7071],\n",
      "        [0.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "S,I = tn.tensor.get_local_space('Spin', 1/2)\n",
    "print(S[:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb07666f",
   "metadata": {},
   "source": [
    "### Contraction\n",
    "\n",
    "- **`library=\"einsum\"`**  \n",
    "  Calls `einsum` from the selected backend (`torch.einsum`, `numpy.einsum`, or `cupy.einsum`).  \n",
    "  This option is generally the most efficient for contractions involving **two tensors**.\n",
    "\n",
    "- **`library=\"cuquantum\"`**  \n",
    "  Uses `cuquantum.tensornet.contract`, which automatically optimizes the contraction path.  \n",
    "  Recommended when contracting **three or more tensors**, and the optimal path is not determined.   \n",
    "  This option is not available without a cuda environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "mNxCwzh2-4HY",
   "metadata": {
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1755785294422,
     "user": {
      "displayName": "Subin Kim",
      "userId": "15547911492359629778"
     },
     "user_tz": -540
    },
    "id": "mNxCwzh2-4HY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 11, 20, 15])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "d = 20\n",
    "t1 = tn.backend.get_rand([10,12,d]) # abi\n",
    "t2 = tn.backend.get_rand([11,13,d,d]) # cjid\n",
    "t3 = tn.backend.get_rand([12,15,13]) #bej\n",
    "\n",
    "# Default: einsum\n",
    "A = tn.tensor.contract('abi,cjid->abcjd', t1, t2)\n",
    "A = tn.tensor.contract('abcjd,bej->acde',A,t3)\n",
    "\n",
    "# CuQuantum\n",
    "# A = tn.tensor.contract('abi,cjid,bej->acde', t1, t2, t3, library='cuquantum')\n",
    "\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c383753e",
   "metadata": {},
   "source": [
    "### Decompositions\n",
    "\n",
    "Singular Value Decomposition (SVD) and QR decomposition are available.  \n",
    "To run without a CUDA environment, specify `use_cuda=False`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86Rz4uCIV5Uk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4587,
     "status": "ok",
     "timestamp": 1755788748038,
     "user": {
      "displayName": "Subin Kim",
      "userId": "15547911492359629778"
     },
     "user_tz": -540
    },
    "id": "86Rz4uCIV5Uk",
    "outputId": "6dee121a-e393-4256-cb82-9b498be510e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 1000, 6])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n"
     ]
    }
   ],
   "source": [
    "t = tn.backend.get_rand([1000, 1000, 6])\n",
    "\n",
    "u, s, v = tn.tensor.svd('ijx->ikx,kj',t,use_cuda=False)\n",
    "# q ,r = tn.tensor.qr('ijx->ikx,kj',t)\n",
    "\n",
    "print(u.shape)\n",
    "print(tn.backend.diag(s).shape)\n",
    "print(v.shape)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
